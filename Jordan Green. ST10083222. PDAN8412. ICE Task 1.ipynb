{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Import Libraries"
      ],
      "metadata": {
        "id": "_E-gcATTwxv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "mWoYr0OZxKu5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Set Up Dataset Path"
      ],
      "metadata": {
        "id": "ywDHUMpIwxn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to your folder containing images\n",
        "data_dir = pathlib.Path('DATA/Nicolas_Cage_Photos')\n"
      ],
      "metadata": {
        "id": "67IhwkMKxLez"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Adjust Parameters"
      ],
      "metadata": {
        "id": "qT-yxFMiwxgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters - can be adjusted\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 100\n",
        "epochs = 20\n"
      ],
      "metadata": {
        "id": "oKOP0RiexL7-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Load Dataset for Training and Validation"
      ],
      "metadata": {
        "id": "AUPpOMEFwxZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing and augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load the dataset for training\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Load the dataset for validation\n",
        "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "\n",
        "# Print number of files in validation set\n",
        "print(f'Validation dataset size: {tf.data.experimental.cardinality(validation_dataset).numpy()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF9tQz5yxMaD",
        "outputId": "b4307d5b-a770-4e21-f780-dd5c7e28b023"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 61 files belonging to 2 classes.\n",
            "Using 49 files for training.\n",
            "Found 61 files belonging to 2 classes.\n",
            "Using 12 files for validation.\n",
            "Validation dataset size: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create Image Classifier Model"
      ],
      "metadata": {
        "id": "-CTCNAMKwxSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "# Print validation dataset size\n",
        "print(f'Validation dataset size: {tf.data.experimental.cardinality(validation_dataset).numpy()}')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byVP859kxNJL",
        "outputId": "e6632488-b465-492c-b713-cc256e059915"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation dataset size: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Compile the Model"
      ],
      "metadata": {
        "id": "l9OthPw_wxLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print validation dataset size\n",
        "print(f'Validation dataset size: {tf.data.experimental.cardinality(validation_dataset).numpy()}')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "TQNHUe6ixNsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Train the Model"
      ],
      "metadata": {
        "id": "Ww1tCvZgwxEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate steps per epoch and validation steps\n",
        "train_steps = tf.data.experimental.cardinality(train_dataset).numpy()\n",
        "validation_steps = tf.data.experimental.cardinality(validation_dataset).numpy()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_data=validation_dataset,\n",
        "    validation_steps=validation_steps\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "Ez_woCLpxODW",
        "outputId": "5db1d59d-fc7b-41fa-d1c9-91aa47cb3fb8"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28s/step - accuracy: 0.5510 - loss: 0.7481 - val_accuracy: 0.4167 - val_loss: 0.8481\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'items'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-409b36de32c5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    352\u001b[0m                 )\n\u001b[1;32m    353\u001b[0m                 val_logs = {\n\u001b[0;32m--> 354\u001b[0;31m                     \u001b[0;34m\"val_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m                 }\n\u001b[1;32m    356\u001b[0m                 \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Function to Display Sample Images"
      ],
      "metadata": {
        "id": "_kirVSZoww9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display sample images from the training set\n",
        "def display_sample_images(train_dataset):\n",
        "    class_names = train_dataset.class_names\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for images, labels in train_dataset.take(1):\n",
        "        for i in range(9):\n",
        "            ax = plt.subplot(3, 3, i + 1)\n",
        "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "            plt.title(class_names[labels[i]])\n",
        "            plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to display sample images\n",
        "display_sample_images(train_dataset)\n"
      ],
      "metadata": {
        "id": "wE1wa7asxOtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Model Data Summary"
      ],
      "metadata": {
        "id": "UgLXta3Www2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "EG40YslyxO_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Visualization for Model Accuracy and Loss"
      ],
      "metadata": {
        "id": "l9J024l3wwvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b4ZrCL5QxPRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Final Results"
      ],
      "metadata": {
        "id": "I3igibpMwwo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final results of the model (Optional)\n",
        "print(\"Final Training Accuracy:\", history.history['accuracy'][-1])\n",
        "print(\"Final Validation Accuracy:\", history.history['val_accuracy'][-1])\n",
        "print(\"Final Training Loss:\", history.history['loss'][-1])\n",
        "print(\"Final Validation Loss:\", history.history['val_loss'][-1])\n"
      ],
      "metadata": {
        "id": "cjtBqj5yxPjM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}